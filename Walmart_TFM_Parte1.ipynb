{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ba6d9b",
   "metadata": {},
   "source": [
    "<img src=https://image.shutterstock.com/image-photo/kazan-russian-federation-aug-5-600w-1211046340.jpg>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4bd99",
   "metadata": {},
   "source": [
    "### 1.Introduccion\n",
    "\n",
    "Se proporcionan datos históricos de ventas para 45 tiendas Walmart ubicadas en diferentes regiones. Cada tienda contiene varios departamentos y se tiene la tarea de predecir las ventas de todo el departamento para cada tienda.\n",
    "Además, Walmart organiza varios eventos promocionales de rebajas durante todo el año. Estas rebajas preceden a los feriados importantes, los cuatro más grandes de los cuales son el Super Bowl, el Labor Day, Thanksgiving y Christmas. Las semanas que incluyen estos días festivos se ponderan cinco veces más en la evaluación que las semanas que no son festivos. Parte del desafío que presenta esta competencia es modelar los efectos de las rebajas en estas semanas de vacaciones en ausencia de datos históricos completos / ideales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b803206",
   "metadata": {},
   "source": [
    "### 2. Importar Librerías & Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c977a2c",
   "metadata": {},
   "source": [
    "###  2.1 Librerías a importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b1ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: notebook-as-pdf in c:\\users\\cesar\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from notebook-as-pdf) (6.0.7)\n",
      "Requirement already satisfied: pyppeteer in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from notebook-as-pdf) (0.2.6)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from notebook-as-pdf) (1.26.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (1.4.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (2.11.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.5.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (5.0.5)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (4.7.1)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (5.1.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.4.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (3.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.1.2)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->notebook-as-pdf) (1.1.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (1.10)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (6.1.12)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (1.5.1)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (2.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (20.0.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert->notebook-as-pdf) (227)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->notebook-as-pdf) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->notebook-as-pdf) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->notebook-as-pdf) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->notebook-as-pdf) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->notebook-as-pdf) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->notebook-as-pdf) (52.0.0.post20210125)\n",
      "Requirement already satisfied: webencodings in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook-as-pdf) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook-as-pdf) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook-as-pdf) (2.4.7)\n",
      "Requirement already satisfied: websockets<10.0,>=9.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (9.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (1.26.4)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (3.10.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (4.59.0)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (8.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer->notebook-as-pdf) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/notebook-as-pdf/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyppeteer in c:\\users\\cesar\\anaconda3\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (3.10.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (1.26.4)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (1.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (4.59.0)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (8.2.2)\n",
      "Requirement already satisfied: websockets<10.0,>=9.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pyppeteer) (9.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer) (3.4.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\cesar\\anaconda3\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: pingouin in c:\\users\\cesar\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.24.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (1.7.1)\n",
      "Requirement already satisfied: pandas-flavor>=0.2.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.2.0)\n",
      "Requirement already satisfied: outdated in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.2.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.8.9)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (3.3.4)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (1.2.4)\n",
      "Requirement already satisfied: statsmodels>=0.12.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pingouin) (1.20.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.2->pingouin) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pandas>=1.0->pingouin) (2021.1)\n",
      "Requirement already satisfied: xarray in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pandas-flavor>=0.2.0->pingouin) (0.19.0)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from statsmodels>=0.12.0->pingouin) (0.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from outdated->pingouin) (2.25.1)\n",
      "Requirement already satisfied: littleutils in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from outdated->pingouin) (0.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests->outdated->pingouin) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests->outdated->pingouin) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests->outdated->pingouin) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests->outdated->pingouin) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from scikit-learn->pingouin) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from scikit-learn->pingouin) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=40.4 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from xarray->pandas-flavor>=0.2.0->pingouin) (52.0.0.post20210125)\n",
      "Requirement already satisfied: missingno in c:\\users\\cesar\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from missingno) (0.11.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from missingno) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from missingno) (3.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from missingno) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->missingno) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from seaborn->missingno) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn->missingno) (2021.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/xgboost/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/xgboost/\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\cesar\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-boost\\\\lib\\\\xgboost.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in c:\\users\\cesar\\anaconda3\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.7.1)\n",
      "Requirement already satisfied: deap>=1.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (4.59.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (0.24.1)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.2.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (1.0.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tpot) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cesar\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U notebook-as-pdf\n",
    "!pip install pyppeteer\n",
    "\n",
    "\n",
    "!pip install plotly\n",
    "!pip install pingouin\n",
    "!pip install missingno\n",
    "!pip install xgboost lightgbm --upgrade --quiet\n",
    "!pip install tpot\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pingouin as pg\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14312be3",
   "metadata": {},
   "source": [
    "### 2.2 Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde2bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"features.csv\")\n",
    "sampleSubmission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "stores = pd.read_csv(\"stores.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6fd7d",
   "metadata": {},
   "source": [
    "### 2.3 Inspección inicial\n",
    "Observamos el tipo de dato de cada una de las variables para los diferentes archivos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d4b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store    Date Temperature Fuel_Price MarkDown1 MarkDown2 MarkDown3  \\\n",
       "Type  int64  object     float64    float64   float64   float64   float64   \n",
       "\n",
       "     MarkDown4 MarkDown5      CPI Unemployment IsHoliday  \n",
       "Type   float64   float64  float64      float64      bool  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad7354e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store    Type   Size\n",
       "Type  int64  object  int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stores.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6629f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store   Dept    Date Weekly_Sales IsHoliday\n",
       "Type  int64  int64  object      float64      bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc34e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store   Dept    Date IsHoliday\n",
       "Type  int64  int64  object      bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a5154",
   "metadata": {},
   "source": [
    "Evaluamos la cantidad de filas y columnas en cada uno de los datasets. Observamos que train y test comprenden el 78% y 22% respectivamente del total de los datos de las 45 tiendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48eb6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8190, 12)\n",
      "(45, 3)\n",
      "(421570, 5)\n",
      "(115064, 4)\n",
      "El ratio de train data : test data es  (79, 21)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(stores.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(\"El ratio de train data : test data es \", \n",
    "      (round(train.shape[0]*100/(train.shape[0]+test.shape[0])),100-round(train.shape[0]*100/(train.shape[0]+test.shape[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f595dc",
   "metadata": {},
   "source": [
    "¿Qué información hemos obtenido hasta ahora?\n",
    "\n",
    "* El dataset _'features', 'train' y 'test'_ poseen la fecha en formato objet y debe ser modificada.\n",
    "* El dataset 'stores' posee 45 filas correspondientes al número de tiendas que vamos a analizar\n",
    "* Los conjuntos _'train'_ y _'test_ comprenden el 78% y 22% respectivamente del total de los datos de estudio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04352c",
   "metadata": {},
   "source": [
    "###  2.4 Merge de datasets 'features' y 'stores'\n",
    "\n",
    "Vamos a crear un nuevo dataset en el que a 'Features' le vamos a incluir el área de la tienda, así como su tipo que \n",
    "aparecen en 'Stores' utilizando como elemento común entre ambos la columna 'Store' siendo la unión a través de inner join.\n",
    "Comprobamos que el nuevo dataset \"feature_store\" posee las 8190 filas, pero con 14 variables en vez de 12 para las 45 tiendas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb3f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = features.merge(stores, how='inner', on = \"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef1b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de filas y columnas es de:  (8190, 14)\n",
      "Existen 45 tiendas unicas\n"
     ]
    }
   ],
   "source": [
    "print(\"El numero de filas y columnas es de: \",(feature_store.shape))\n",
    "print(\"Existen\",(len(feature_store.Store.unique())), 'tiendas unicas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae0747",
   "metadata": {},
   "source": [
    "### 2.5 Merge de datasets 'train' & 'feature_store'\n",
    "\n",
    "Realizamos la operación para los dataset 'train' & 'feature_store'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e41809b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train.merge(feature_store, how='inner', \n",
    "                       on = ['Store','Date','IsHoliday']).sort_values(by=['Store','Dept','Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "484270d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de filas y columnas es de:  (421570, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"El numero de filas y columnas es de: \",(train_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9a68b",
   "metadata": {},
   "source": [
    "### 2.6 Merge de datasets 'test' & 'feature_store'\n",
    "\n",
    "Realizamos la misma operación para los dataset 'test' & 'feature_store'. El nuevo dataset mantiene las mismas filas\n",
    "que 'test' y tiene las mismas variables que 'train’ a excepción de 'Weekly_Sales'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3e4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.merge(feature_store, how='inner', \n",
    "                     on = ['Store','Date','IsHoliday']).sort_values(by = ['Store','Dept','Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7f6dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de filas y columnas es de:  (115064, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"El numero de filas y columnas es de: \",(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c0874",
   "metadata": {},
   "source": [
    "### 2.7 Convertir columna \"Date\" a formato datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f5d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "\n",
    "print(train_df[\"Date\"].dtypes)\n",
    "print(test_df[\"Date\"].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f5a2c2",
   "metadata": {},
   "source": [
    "### 2.8 Descomponemos la fecha creando nuevas variables 'Day','Week','Month','Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1dcc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de filas y columnas es de:  (421570, 20)\n",
      "El numero de filas y columnas es de:  (115064, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df['Day'] = train_df['Date'].dt.day\n",
    "train_df['Week'] = train_df['Date'].dt.week\n",
    "train_df['Month'] = train_df['Date'].dt.month\n",
    "train_df['Year'] = train_df['Date'].dt.year\n",
    "\n",
    "\n",
    "test_df['Day'] = test_df['Date'].dt.day\n",
    "test_df['Week'] = test_df['Date'].dt.week\n",
    "test_df['Month'] = test_df['Date'].dt.month\n",
    "test_df['Year'] = test_df['Date'].dt.year\n",
    "\n",
    "print(\"El numero de filas y columnas es de: \",(train_df.shape))\n",
    "print(\"El numero de filas y columnas es de: \",(test_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b30b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.5</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1 2010-02-05       24924.5      False        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
       "\n",
       "   Unemployment Type    Size  Day  Week  Month  Year  \n",
       "0         8.106    A  151315    5     5      2  2010  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb8d3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>False</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  IsHoliday  Temperature  Fuel_Price  MarkDown1  \\\n",
       "0      1     1 2012-11-02      False        55.32       3.386    6766.44   \n",
       "\n",
       "   MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment Type  \\\n",
       "0     5147.7      50.82     3639.9    2737.42  223.462779         6.573    A   \n",
       "\n",
       "     Size  Day  Week  Month  Year  \n",
       "0  151315    2    44     11  2012  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec650c3",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e1b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = train_df.copy()\n",
    "data_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47739967",
   "metadata": {},
   "source": [
    "### 4.1 Feature Engineering Nueva variable:  Semanas Clave\n",
    "\n",
    "\n",
    "Se van a crear cuatro nuevas variables que corresponden a aquellas semanas que se consideran claves en las ventas, estas serían:\n",
    "\n",
    "* SuperBowlWeek: Semana 6 del año.\n",
    "* LaborDay: Semana 36 del año.\n",
    "* Thanksgiving: Semana 47 del año.\n",
    "* Christmas: Semana 52 del año.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6d4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['SuperBowlWeek'] = train_df['Week'].apply(lambda x: 1 if x == 6 else 0)\n",
    "data_train['LaborDay'] = train_df['Week'].apply(lambda x: 1 if x == 36 else 0)\n",
    "data_train['Thanksgiving'] = train_df['Week'].apply(lambda x: 1 if x == 47 else 0)\n",
    "data_train['Christmas'] = train_df['Week'].apply(lambda x: 1 if x == 52 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc139a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['SuperBowlWeek'] = test_df['Week'].apply(lambda x: 1 if x == 6 else 0)\n",
    "data_test['LaborDay'] = test_df['Week'].apply(lambda x: 1 if x == 36 else 0)\n",
    "data_test['Thanksgiving'] = test_df['Week'].apply(lambda x: 1 if x == 47 else 0)\n",
    "data_test['Christmas'] = test_df['Week'].apply(lambda x: 1 if x == 52 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebae26",
   "metadata": {},
   "source": [
    "###  4.2 Feature Engineering nueva variable: Quarter\n",
    "\n",
    "\n",
    "Agrupamos las semanas por trimestre Q1, Q2,Q3 y Q4. El motivo es para conocer si las ventas y las promociones estan sujetas a los resultados trimestrales que pueda ofrecer la empresa.\n",
    "\n",
    "* Q1:Semana de la 1 a la 13.\n",
    "* Q2:Semana de la 14 a la 26.\n",
    "* Q3:Semana de la 27 a la 39.\n",
    "* Q4:Semana de la 40 a la 52.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4b30259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.insert(24,'Quarter',data_train['Week'])\n",
    "data_test.insert(23,'Quarter',data_test['Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97c59388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Quarter'] = data_train['Quarter'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], 1)\n",
    "data_train['Quarter'] = data_train['Quarter'].replace([14,15,16,17,18,19,20,21,22,23,24,25,26], 2)\n",
    "data_train['Quarter'] = data_train['Quarter'].replace([27,28,29,30,31,32,33,34,35,36,37,38,39], 3)\n",
    "data_train['Quarter'] = data_train['Quarter'].replace([40,41,42,43,44,45,46,47,48,49,50,51,52], 4)\n",
    "\n",
    "data_test['Quarter'] = data_train['Quarter'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], 1)\n",
    "data_test['Quarter'] = data_train['Quarter'].replace([14,15,16,17,18,19,20,21,22,23,24,25,26], 2)\n",
    "data_test['Quarter'] = data_train['Quarter'].replace([27,28,29,30,31,32,33,34,35,36,37,38,39], 3)\n",
    "data_test['Quarter'] = data_train['Quarter'].replace([40,41,42,43,44,45,46,47,48,49,50,51,52], 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6849fa42",
   "metadata": {},
   "source": [
    "### 4.3 Feature Engineering nueva variable: Rebajas\n",
    "\n",
    "\n",
    "Creamos una nueva variable 'MarkdownSum' que será el sumatorio de las cuatro promociones Markdown. En caso de que 2 promociones se solapen en el tiempo se verá reflejado en el sumatorio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4135e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['MarkdownsSum'] = train_df['MarkDown1'] + train_df['MarkDown2'] + train_df['MarkDown3'] + train_df['MarkDown4'] + train_df['MarkDown5']\n",
    "data_test['MarkdownsSum'] = test_df['MarkDown1'] + test_df['MarkDown2'] + test_df['MarkDown3'] + test_df['MarkDown4'] + test_df['MarkDown5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2944ed7",
   "metadata": {},
   "source": [
    "### 4.4 Feature Engineering: Rellenar valores missing\n",
    "\n",
    "Podemos comprobar en los gráficos adjuntos la ausencia de bastantes valores en las variables de las rebajas, CPI y Unemployment.\n",
    "\n",
    "Las rebajas cuando sean NA el valor será sustituido por 0, CPI y Unemployment serán rellenos por la media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48650329",
   "metadata": {},
   "source": [
    "#### 4.4.1 Observamos los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecffd42f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 125. MiB for an array with shape (421570, 26, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9c4608ec80d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Package called missingno (https://github.com/ResidentMario/missingno) !pip install quilt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmsno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\missingno\\missingno.py\u001b[0m in \u001b[0;36mmatrix\u001b[1;34m(df, filter, n, p, sort, figsize, width_ratios, color, fontsize, labels, sparkline, inline, freq, ax)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# z is the color-mask array, g is a NxNx3 matrix. Apply the z color-mask to set the RGB of each pixel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 125. MiB for an array with shape (421570, 26, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "#Package called missingno (https://github.com/ResidentMario/missingno) !pip install quilt\n",
    "import missingno as msno\n",
    "msno.matrix(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaca937",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumatorio de valores missing para el dataset 'train'.\n",
    "print('Datos missing en data_train')\n",
    "print('---------------------')\n",
    "print(data_train.isna().sum())\n",
    "print('')\n",
    "print('Datos missing en data_test')\n",
    "print('---------------------')\n",
    "print(data_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b71ca",
   "metadata": {},
   "source": [
    "#### 4.4.2 Los valores missing en 'data_train' los rellenamos con el valor '0'.\n",
    "\n",
    "Para el caso de 'data_train' solo se observan valores missing en las variables Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a585f42",
   "metadata": {},
   "source": [
    "#### 4.4.3 Los valores missing en 'data_test' correspondientes a 'CPI' y 'Unemployment' los rellenamos con la media.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3493458",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['CPI'].fillna(data_test['CPI'].mean(), inplace = True)\n",
    "data_test['Unemployment'].fillna(data_test['Unemployment'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores missing en 'test' que corresponden solamente a las rebajas los rellenamos con \"0\"\n",
    "data_test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04232fd6",
   "metadata": {},
   "source": [
    "### 4.5 Feature Engineering: IsHoliday Encoding Categorical Data\n",
    "\n",
    "La variable 'IsHoliday' tendrá valor 1 si su valor original es 'True' y 'False' en caso contrario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4118ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['IsHoliday'] = data_train['IsHoliday'].apply(lambda x: 1 if x == True else 0)\n",
    "data_test['IsHoliday'] = data_test['IsHoliday'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91f03c",
   "metadata": {},
   "source": [
    "###  4.6 Feature Engineering : Type  Encoding Categorical Data.\n",
    "\n",
    "la variable 'Type' tendra valor 1 si la tienda era de la categoria A, 2 si es de la categoria B y 3 si es de la categoria C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Type'] = data_train['Type'].apply(lambda x: 1 if x == 'A' else (2 if x == 'B' else 3))\n",
    "data_test['Type'] = data_test['Type'].apply(lambda x: 1 if x == 'A' else (2 if x == 'B' else 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de054d1",
   "metadata": {},
   "source": [
    "### 4.7 Feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a1922",
   "metadata": {},
   "source": [
    "#### Selección de variables\n",
    "\n",
    "Una vez rellenos los valores missing observamos que las variables que poseen más correlación con las ventas semanales son el tamaño de la tienda, el departamento, así como las diferentes campañas de rebajas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df074115",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.corr()['Weekly_Sales'][:5].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac65fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos el tipo de dato de cada una de las variables  para los diferentes archivos:\n",
    "pd.DataFrame(data_train.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f = data_train.drop(['Date','Weekly_Sales'], axis = 'columns' )\n",
    "y_f = data_train['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a164f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_features = RandomForestRegressor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599350bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_features.fit(X_f, y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_f.columns,\n",
    "    'importance': rf_features.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Feature Importance')\n",
    "sns.barplot(data=importance_df.head(26), x='importance', y='feature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631acb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_vif = data_train.copy(deep = True)\n",
    "features = list(dt_vif.columns)\n",
    "features.remove('Weekly_Sales') # Borrado de la variable objetivo\n",
    "features.remove('Date') # Una variable en formato Date no puede ser procesada por la funcion.\n",
    "dt_vif = dt_vif[features]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    var = features[i]\n",
    "    fet = features[:]\n",
    "    fet.remove(var)\n",
    "    \n",
    "    x = dt_vif[fet]\n",
    "    y = data_train[var]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    vif = 1 / (1 - model.score(x, y))\n",
    "    \n",
    "    print ('El valor del VIF para la variable', var, 'es:', vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064cec5",
   "metadata": {},
   "source": [
    "Se observan algunas variables que tienen un VIF superior a 5 y algunos valores son muy elevados, procederemos a irlas eliminando y ejecutaremos el proceso nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_vif = data_train.copy(deep = True)\n",
    "features = list(dt_vif.columns)\n",
    "features.remove('Weekly_Sales')\n",
    "features.remove('Date')\n",
    "features.remove('MarkdownsSum') # Eliminamos esta variable por ser la que posee mas VIF del conjunto Markdown\n",
    "features.remove('Week') # Eliminamos la variable Week por tener un VIF de 40,090\n",
    "dt_vif = dt_vif[features]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    var = features[i]\n",
    "    fet = features[:]\n",
    "    fet.remove(var)\n",
    "    \n",
    "    x = dt_vif[fet]\n",
    "    y = data_train[var]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    vif = 1 / (1 - model.score(x, y))\n",
    "    \n",
    "    print ('El valor del VIF para la variable', var, 'es:', vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_vif = data_train.copy(deep = True)\n",
    "features = list(dt_vif.columns)\n",
    "features.remove('Weekly_Sales')\n",
    "features.remove('Date')\n",
    "features.remove('MarkdownsSum') \n",
    "features.remove('Week') \n",
    "features.remove('Quarter') # Esta variable es la siguientye candidata por tener un VIF de 15\n",
    "\n",
    "\n",
    "dt_vif = dt_vif[features]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    var = features[i]\n",
    "    fet = features[:]\n",
    "    fet.remove(var)\n",
    "    \n",
    "    x = dt_vif[fet]\n",
    "    y = data_train[var]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    vif = 1 / (1 - model.score(x, y))\n",
    "    \n",
    "    print ('El valor del VIF para la variable', var, 'es:', vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b3fd0",
   "metadata": {},
   "source": [
    "Existen algunas variables que presentan valor infinito por tanto eliminamos la siguiente variable\n",
    "   * Eliminar la variable IsHoliday\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5142dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_vif = data_train.copy(deep = True)\n",
    "features = list(dt_vif.columns)\n",
    "features.remove('Weekly_Sales')\n",
    "features.remove('Date')\n",
    "features.remove('MarkdownsSum') \n",
    "features.remove('Week') \n",
    "features.remove('Quarter') \n",
    "features.remove('IsHoliday') # Eliminamos IsHoliday por tener valor Inf.\n",
    "\n",
    "\n",
    "dt_vif = dt_vif[features]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    var = features[i]\n",
    "    fet = features[:]\n",
    "    fet.remove(var)\n",
    "    \n",
    "    x = dt_vif[fet]\n",
    "    y = data_train[var]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    vif = 1 / (1 - model.score(x, y))\n",
    "    \n",
    "    print ('El valor del VIF para la variable', var, 'es:', vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290f304",
   "metadata": {},
   "source": [
    "### Guardamos los dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset SIN feature engineering\n",
    "train_df.to_csv('train_df.csv',index=False)\n",
    "test_df.to_csv('test_df.csv',index=False)\n",
    "\n",
    "\n",
    "#Dataset CON feature engineering\n",
    "data_train.to_csv('data_train.csv',index=False)\n",
    "data_test.to_csv('data_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
